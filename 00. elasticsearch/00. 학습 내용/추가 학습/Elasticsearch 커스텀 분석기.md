# Elasticsearch 커스텀 분석기

>  아래는 gemini를 통해 얻은 답변이다.

------

커스텀 분석기 적용 예 :

```json
PUT /movie_custom_analyzer
{
  "settings": {
    "analysis": {
      "filter": {
        "my_stop": {
          "type": "stop",
          "stopwords": ["영화", "작품"]
        },
        "my_synonym": {
          "type": "synonym",
          "synonyms": ["어벤져스,엔드게임 => 어벤져스 엔드게임"]
        }
      },
      "analyzer": {
        "kr_custom": {
          "type": "custom",
          "tokenizer": "nori_tokenizer",
          "filter": ["lowercase", "my_stop", "my_synonym"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "title": { "type": "text", "analyzer": "kr_custom" }
    }
  }
}
```

제시해주신 코드는 `Elasticsearch`에서 **한국어 검색의 정확도를 높이기 위해** 매우 중요한 세 가지 요소, 즉 커스텀 분석기(Custom Analyzer), 불용어(Stopwords), 유의어(Synonyms)를 설정하는 완벽한 예시입니다.

이러한 요소들은 검색 엔진이 텍스트를 처리하고 저장하는 방식인 텍스트 분석(Text Analysis)의 핵심 개념입니다.

## 1. 커스텀 분석기 (Custom Analyzer)

커스텀 분석기는 `Elasticsearch`가 텍스트를 검색 가능한 토큰(Token)으로 변환하는 전체 과정을 사용자가 직접 정의하는 것입니다. 분석 과정은 '토크나이저'와 '필터'의 조합으로 이루어집니다.

| 구성 요소            | 예시 코드에서의 역할                 | 설명                                                         |
| -------------------- | ------------------------------------ | ------------------------------------------------------------ |
| **`tokenizer`**      | `nori_tokenizer`                     | 입력된 텍스트를 가장 먼저 받아서 의미 있는 조각(토큰)으로 나눕니다. 한국어에서는 **형태소 분석**을 담당합니다. |
| **`filter`**         | `lowercase`, `my_stop`, `my_synonym` | 토크나이저가 만든 토큰 목록을 순서대로 받아들여 **변형하거나 제거**하는 역할을 합니다. |
| **`type: "custom"`** | `kr_custom`                          | 사용자 정의 분석기를 생성하겠다는 의미입니다.                |

예시 작동 순서 (`kr_custom`):

1. 입력 텍스트: "최고의 영화 어벤져스,엔드게임 작품"
2. `nori_tokenizer`: 텍스트를 형태소로 분리합니다. (예: `최고`, `의`, `영화`, `어벤져스`, `,`, `엔드게임`, `작품`)
3. `lowercase` 필터: 모든 토큰을 소문자로 변환합니다. (한국어에서는 크게 필요 없지만, 영어가 섞인 경우 유용)
4. `my_stop` 필터 (불용어): `영화`, `작품` 토큰을 제거합니다.
5. `my_synonym` 필터 (유의어): `어벤져스,엔드게임`을 찾아 `어벤져스 엔드게임` 토큰으로 대체/변환합니다.
6. 최종 저장 토큰: `최고`, `의`, `어벤져스`, `엔드게임` (또는 Nori 설정에 따라 다름)

## 2. 불용어 (Stopwords)

**불용어**는 검색 결과에 거의 영향을 주지 않거나, 너무 자주 등장하여 검색의 효율을 떨어뜨리는 단어들을 의미합니다.

- `my_stop` 설정:

  ```json
  "my_stop": {
    "type": "stop",
    "stopwords": ["영화", "작품"] 
  }
  ```

- 역할: 위 설정에서 "영화"나 "작품"이라는 단어는 사용자가 어떤 영화를 검색하더라도 흔하게 사용될 수 있습니다. 이 단어들을 인덱스에서 제거하면, 인덱스 크기가 줄어들고, 다른 중요한 키워드(예: 배우 이름, 감독, 제목)에 대한 검색 점수(score)가 상대적으로 높아져 검색 정확도를 개선하는 효과를 줍니다.

## 3. 유의어 (Synonyms)

**유의어**는 서로 다른 단어를 같은 의미로 취급하여 검색 범위를 확장하는 데 사용됩니다. 사용자가 검색한 단어와 문서에 저장된 단어가 다르더라도 매칭시켜줍니다.

- **`my_synonym` 설정:**

  ```json
  "my_synonym": {
    "type": "synonym",
    "synonyms": ["어벤져스,엔드게임 => 어벤져스 엔드게임"]
  }
  ```

- **작동 방식:**

  - A, B ⇒ C (Many to One): 검색 시 A나 B를 입력하면 인덱스에는 C로 검색됩니다. 혹은 인덱싱 시 A와 B를 C로 저장합니다.
  - A ⇒ B,C (One to Many): 검색 시 A를 입력하면 B와 C 모두로 검색합니다.
  - 코드 예시의 문제점: 제시된 유의어 설정 `어벤져스,엔드게임 => 어벤져스 엔드게임`은 다소 복잡한 형태입니다.
    - 일반적으로 Nori는 쉼표(`,`)를 토큰 분리자로 인식할 수 있으므로, 사용자의 의도는 "'어벤져스,엔드게임'을 붙여서 하나의 토큰인 '어벤져스 엔드게임'으로 인식"하거나 "두 단어를 검색 시 동일하게 취급"하려는 것일 수 있습니다.
    - 더 일반적이고 명확한 유의어 설정은 다음과 같습니다:
      - 확장 검색: `"어벤져스 엔드게임, 어벤져스4"` (둘 중 하나를 검색해도 둘 다 나오게 함)
      - 변환: `"어벤져스4 => 어벤져스 엔드게임"` (어벤져스4로 검색하면 '어벤져스 엔드게임'으로 변환)

## 4. 매핑 (Mappings)

마지막으로 `mappings` 섹션에서 정의된 `kr_custom` 분석기를 실제 필드에 적용합니다.

```json
"mappings": {
  "properties": {
    "title": { "type": "text", "analyzer": "kr_custom" }
  }
}
```

- `title` 필드의 `type`을 `text`로 지정하고, 색인 시 사용할 분석기로 위에서 정의한 **`kr_custom`** 분석기를 사용하도록 명시합니다. 이제 이 인덱스에 저장되는 모든 `title` 값은 Nori 형태소 분석, 불용어 제거, 유의어 처리를 거쳐 저장됩니다.