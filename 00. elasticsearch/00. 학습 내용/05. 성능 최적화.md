# 05. 성능 최적화

---



## 1) 샤드(Shard)와 레플리카(Replica) 설정 전략

### 원칙

- **오버샤딩 금지**: “작은 인덱스에 많은 샤드”는 오버헤드만 키움.
- **샤드당 권장 크기**: 운영 기준 보통 **20~50GB/primary shard**를 sweet spot으로 본다.
- **초기 설계**: 학습/개발은 보통 `1 primary`, `1 replica`로 시작.
- **검색 트래픽↑**이면 Replica를 늘려 조회 분산. **색인 트래픽↑**이면 Primary를 분할(인덱스 분리/샤드 수 증가) 혹은 파티셔닝.

### 실습 권장 (개발/소규모)

```json
PUT /movies_v2/_settings
{
  "index": {
    "number_of_replicas": 1
  }
}
```

### 대용량 신규 색인 배치 시(초기 로드 최적화)

1. 임시로 **Replica=0**, **refresh_interval↑**
2. 대량 색인 후 force merge(선택), 마지막에 Replica 복구 & refresh 정상화

```json
PUT /movies_v2/_settings
{
  "index": {
    "number_of_replicas": 0,
    "refresh_interval": "60s"
  }
}
# 대량 색인 수행…

# (선택) 세그먼트 줄이기 – 검색 전용 read-heavy 인덱스일 때만
POST /movies_v2/_forcemerge?max_num_segments=1

PUT /movies_v2/_settings
{
  "index": {
    "number_of_replicas": 1,
    "refresh_interval": "1s"
  }
}
```

> 실시간성이 덜 중요하면 `refresh_interval`을 5~30s로 올려 색인 TPS 향상.

## 2) 인덱스 성능 튜닝(색인·저장 최적화)

### 매핑/설정

- 정렬·집계 대상 필드는 `keyword`/numeric/date + `doc_values: true`(기본) 사용.
- `text` 필드에 집계/정렬이 필요하면 multi-field로 `keyword` 추가.
- 불필요한 필드/서브필드 제거: 저장/메모리/세그먼트 감소.
- `_source`는 업데이트/재색인/하이라이트에 필요. 완전 제거는 비추. 대신 `_source`의 **`includes/excludes`*로 저장량 줄이기 고려.
- 압축: 저장 공간 절약 – CPU 비용과 트레이드오프.

```json
PUT /movies_v2/_settings
{
  "index": {
    "codec": "best_compression"   // 저장 공간 ↓ (색인/CPU↑)
  }
}
```

### 색인 최적화

- **Bulk 크기**: 일반적으로 **5~15MB / 1,000~5,000 docs** 단위가 안정적.
- **병렬성**: CPU/IO 고려해 워커 늘리되, shard 수보다 과도하면 역효과.
- **자동 생성 필드 최소화**: dynamic mapping 남발 금지 → 명시 매핑.
- **필요 시 Index Lifecycle(ILM)**: 오래된 데이터 rollover/압축/삭제.

## 3) 검색 성능 최적화 기법

### 쿼리 설계

- **Filter Context 적극 활용**: 스코어 계산이 불필요한 조건은 `filter`로. 캐시 탑재 ↓CPU.
- **정확 일치/집계는 `keyword`** 사용. `text`에 `term` 금지(분석된 토큰과 안 맞음).
- **페이징**: 대페이지는 `from/size` 대신 **`search_after` + 정렬 키** 사용.
- **집계 전용 인덱스 정렬**: 자주 정렬하는 필드 미리 정렬해 merge 단계 최적화.

```json
PUT /movies_v2/_settings
{
  "index": {
    "sort.field": "year",
    "sort.order": "desc"
  }
}
```

---

### 🚨 트러블슈팅

`index.sort.*`는 정적(static) 설정이므로 인덱스가 열린(open) 상태에서는 바꿀 수 없다. 그래서 현재 상태에서 위 `_settings`를 요청하면 실패한다. `reopen=true`로 재오픈을 트리거하거나, 일반적으로 **close → settings → open** 순서로 작업해야 한다.

가장 이상적으로는 애초에 인덱스 생성 시점에 `index.sort.*` 를 지정하고 사용하거나, 재색인하는 게 낫다.

**올바른 절차**

```json
POST /movies_v2/_close
# close 이후에는 검색(search 등) 결과가 안 나온다.

PUT /movies_v2/_settings
{
  "index": {
    "sort.field": "year",
    "sort.order": "desc"
  }
}

POST /movies_v2/_open
```

**중요 주의점**

- `index.sort.*`는 **세그먼트 작성/병합 시점부터** 적용됩니다. 기존 세그먼트 순서는 곧바로 바뀌지 않습니다. 빠르게 반영하고 싶다면 **forcemerge**로 세그먼트를 재작성하세요:

  ```json
  POST /movies_v2/_forcemerge?max_num_segments=1
  ```

…가 아니었다. `close` 요청 후에도 여전히 `index.sort` 설정은 변경할 수 없는 내용이었다. ~~chatGPT 구라쟁이~~.

이를 위해서는 **최초 인덱스 생성 시에 설정해야** 한다. 그러므로 현재 상황에서 반영하고자 한다면 신규 인덱스 ex. `movie_v3`를 만들어서 `index.sort` 적용 후 재색인(reindex)을 해야한다는 것이다. 일단 여기서는 넘어가겠다. (재색인은 앞선 [04. 고급 검색 쿼리](04.%20고급%20검색%20쿼리.md)에서 수행해봤다)

---

- **불필요한 전체 count 금지**: `track_total_hits: false` 또는 특정 상한 사용.
- **응답 크기 줄이기**: `_source` 필터링으로 네트워크와 디코딩 비용↓

```json
GET /movies_v2/_search
{
  "_source": ["title","year","rating"],    // 필요한 필드만
  "track_total_hits": 10000,               // or false
  "query": { "match_all": {} },
  "size": 20
}
```

→ 응답 결과

```json
 {
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 5,
      "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "movies_v2",
        "_id": "1",
        "_score": 1,
        "_source": {
          "title": "어벤져스: 엔드게임",
          "year": 2019,
          "rating": 8.4
        }
      },
      {
        "_index": "movies_v2",
        "_id": "2",
        "_score": 1,
        "_source": {
          "title": "인셉션",
          "year": 2010,
          "rating": 8.8
        }
      },
      {
        "_index": "movies_v2",
        "_id": "3",
        "_score": 1,
        "_source": {
          "title": "기생충",
          "year": 2019,
          "rating": 8.6
        }
      },
      {
        "_index": "movies_v2",
        "_id": "4",
        "_score": 1,
        "_source": {
          "title": "인터스텔라",
          "year": 2014,
          "rating": 8.7
        }
      },
      {
        "_index": "movies_v2",
        "_id": "5",
        "_score": 1,
        "_source": {
          "title": "스파이더맨: 노 웨이 홈",
          "year": 2021,
          "rating": 8.3
        }
      }
    ]
  }
}
```

### 라우팅/파티셔닝 (고급)

- **핫키/테넌트 분리** 필요 시 **custom routing**으로 특정 샤드에 로컬라이즈.
- 예: 사용자 계정, 카테고리(주의: 쏠림 방지 설계 필수)

## 4) 캐싱 전략

### 종류

- **Query cache**(filter context 결과 캐시): 동일 filter 재사용 시 효과↑
- **Request cache**(전체 응답 캐시): 동일 요청(쿼리+정렬+집계)이 반복될 때.
- **OS Page Cache**: 파일 시스템 레벨 – 자주 읽는 세그먼트가 메모리에 상주.

### 실전 팁

- **filter**를 써야 Query cache에 잘 들어감.
- 집계 heavy 대시보드는 **request_cache** 유리(데이터 변동 적을 때).

```json
PUT /movies_v2/_settings
{
  "index": {
    "request_cache": "true"
  }
}
```

- 캐시 미스/히트는 workload/데이터 변경률에 크게 좌우됨 → **키바나 대시보드의 반복 조회** 같은 시나리오에 특히 유효.

---

### 🚨 트러블슈팅

위 요청은 실패한다. 오류 메시지를 보면 `unknown setting [index.request_cache] please check…` 이라고 하는 것으로 보아 명령어가 잘못된 것으로 보인다. 다시 확인해보니 설정명은 `requests.cache.enable`이다.

```json
PUT /movies_v2/_settings
{
  "index": {
    "requests.cache.enable": true
  }
}
```

---

## 5) Refresh Interval 조정

- **색인 TPS vs 검색 최신성**의 절충:
  - 실시간성 중요: `1s` (기본)
  - 배치 색인: `30s`~`60s` (또는 `1`로 비활성화 후 수동 `POST /_refresh`)
- 실습 예)

```json
PUT /movies_v2/_settings
{
  "index": { "refresh_interval": "10s" }
}
```

- 로그/배치 인덱스: ingestion 끝나면 `POST /movies_v2/_refresh` 명시 호출.

## 6) 모니터링과 로깅

### 필수 지표 & 확인 API

- **클러스터 상태**:

  `GET /_cluster/health?level=shards`

  `GET /_cat/nodes?v` / `GET /_cat/indices?v` / `GET /_cat/shards?v`

- **인덱스/세그먼트/필드데이터**:

  `GET /movies_v2/_stats`

  `GET /movies_v2/_stats/fielddata?human=true`

  `GET /_cat/segments/movies_v2?v`

- **핫스레드(병목)**:

  `GET /_nodes/hot_threads?threads=3&type=cpu`

- **할당 이슈 설명**:

  `GET /_cluster/allocation/explain`

### 슬로우 로그(꼭 켜두기)

- **검색 슬로우 로그**

```json
PUT /movies_v2/_settings
{
  "index.search.slowlog.threshold.query.warn":  "2s",
  "index.search.slowlog.threshold.query.info":  "1s",
  "index.search.slowlog.threshold.fetch.info":  "800ms",
  "index.search.slowlog.level":                 "info"
}
```

- **색인 슬로우 로그**

```json
PUT /movies_v2/_settings
{
  "index.indexing.slowlog.threshold.index.warn": "500ms",
  "index.indexing.slowlog.level":                "info"
}
```

> Kibana Stack Monitoring에서 노드/인덱스/검색 대기열·GC·I/O 등도 시각화로 점검.

---

### 🚨 트러블슈팅

오류 메시지를 보면 `[index.search.slowlog.level] setting was deprecated …` 라고 나온다. 설정이 제거되었거나 위치가 바뀐 것으로 보여 확인해봤다.

ES 최신 버전부터 **슬로우 로그의 “레벨(level)”은 인덱스 설정이 아닌 로거(logger) 설정**으로 이동했습니다. 그래서 `index.search.slowlog.level` / `index.indexing.slowlog.level`은 더 이상 지원되지 않아요(삭제됨).

**올바른 설정 방식**

- **임계값(threshold)** 은 여전히 **인덱스 설정**으로 지정
- **로그 레벨** 은 **클러스터 로거**로 지정

(1) 임계값 설정(인덱스 설정)

```json
PUT /movies_v2/_settings
{
  "index.search.slowlog.threshold.query.warn":  "2s",
  "index.search.slowlog.threshold.query.info":  "1s",
  "index.search.slowlog.threshold.fetch.info":  "800ms",

  "index.indexing.slowlog.threshold.index.warn": "500ms"
}
```

(2) 로거 레벨 설정(클러스터 설정)

```json
PUT /_cluster/settings
{
  "transient": {
    "logger.index.search.slowlog":   "INFO",
    "logger.index.indexing.slowlog": "INFO"
  }
}
```

**확인 포인트**

- Kibana → **Stack Monitoring** 또는 **로그 수집 경로**(콘테이너 stdout, 파일 로그 등)에 슬로우 로그가 찍히는지 확인
- 너무 낮은 임계값은 로그 폭증을 부릅니다. 운영은 `info` 수준 + 합리적 기준(수백 ms~수 초)을 추천

## 7) Aggregation/정렬 고급 최적화 요약

- 집계/정렬용 필드는 **`keyword/numeric/date + doc_values`** (기본값 유지).
- **`eager_global_ordinals: true`**: 낮은 지연을 위해 keyword 집계/정렬 초기에 오버헤드를 한 번에.

```json
PUT /movies_v2/_mapping
{
  "properties": {
    "genres": { "type": "keyword", "eager_global_ordinals": true }
  }
}
```

- **runtime fields 남용 금지**: 유연하지만 CPU↑; 자주 쓰면 매핑 필드로 승격.
- **스크립트 기반 집계/정렬 최소화**: Painless는 느림 → 사전정규화/전처리 고려.

## 8) 실전 점검 시나리오(체크리스트)

1. **오버샤딩?** → 샤드 수/크기/세그먼트 확인
2. **색인 튜닝** → bulk 크기/동시성/refresh/replica 조정
3. **쿼리 구조** → filter context, search_after, _source 필터링 적용
4. **캐시 히트** → 동일 패턴 재조회 시 request/query cache 활용
5. **슬로우 로그** → 병목 쿼리 식별 → explain/profile로 재작성
6. **리소스 병목** → hot_threads, GC, I/O 모니터링
7. **장기 운영** → ILM로 rollover + forcemerge(읽기 전용) + snapshot
